[training]
nr_of_epochs = 1_000
save_dir = "training"
experiment_name = "train_on_energies"
accelerator = "gpu"
num_nodes = 1
devices = 1                              #[0,1,2,3]
batch_size = 512
remove_self_energies = true
pin_memory = true

training_parameters.lr = 1e-3
training_parameters.lr_scheduler_config.frequency = 1
training_parameters.lr_scheduler_config.mode = "min"
training_parameters.lr_scheduler_config.factor = 0.1
training_parameters.lr_scheduler_config.patience = 10
training_parameters.lr_scheduler_config.cooldown = 5
training_parameters.lr_scheduler_config.min_lr = 1e-8
training_parameters.lr_scheduler_config.threshold = 0.1
training_parameters.lr_scheduler_config.threshold_mode = "abs"
training_parameters.lr_scheduler_config.monitor = "rmse_val_loss"
training_parameters.lr_scheduler_config.interval = "epoch"

early_stopping.verbose = true
early_stopping.monitor = "rmse_val_loss"
early_stopping.min_delta = 0.001
early_stopping.patience = 50

stochastic_weight_averaging_config.swa_epoch_start=100
stochastic_weight_averaging_config.swa_lrs=1e-2